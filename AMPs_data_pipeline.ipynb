{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMPs data pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdKJ+qkLJ+qlnjHtqTknJD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anvelezec/hans_on/blob/master/AMPs_data_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbScHdehjnsG"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/anvelezec/hans_on/blob/master/AMPs_data_pipeline.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeKHw9xx4p0Y"
      },
      "source": [
        "!pip install -q tfds-nightly"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXrg66Gu4syf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrvJTJXZjmMC"
      },
      "source": [
        "# Data base consolidation\n",
        "There are plenty of antimicrobial peptides (AMPs) databases on the web, some useful links that centralize universities, research groups or laboratories metadata to download them are:\n",
        "* http://crdd.osdd.net/raghava/satpdb/links.php\n",
        "* http://www.uwm.edu.pl/biochemia/index.php/en/biopep/32-bioactive-peptide-databases\n",
        " \n",
        "Sometimes the discovered AMPs are able to be downloaded in a fasta, csv or txt format. In other occasions we should use web scraping to consolidate peptides and its properties.\n",
        " \n",
        "During this notebook we are going to focus on the data pipeline creation, and we are using a toy database of 5  AMPs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reh5I_mxjfL0"
      },
      "source": [
        "amps_toy = [\"MPKTRRRPRRSQRKRPPTPWPYGRKKRRQRRR\",\n",
        "            \"KLWKLWLKWLL\",\n",
        "            \"GINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYE\",\n",
        "            \"IKELLPHLSGIIDSVANAIK\",\n",
        "            \"FLPLIGKVLSSIL\"]\n",
        "\n",
        "with open(\"AMPs_toy.txt\", \"w\") as file:\n",
        "  for amp in amps_toy:\n",
        "    file.write(amp + \"\\n\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxDpgka6cfp-"
      },
      "source": [
        "# 1. Step load dataset with tf.data.TextLineDataset\n",
        "Since we would not load all our dataset in memory we use tf.data.TextLineDataset to read batches of AMPs and feed them into a model. This way we could scale our computing capacity at different dataset sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj_-bnsD4_1D"
      },
      "source": [
        "tf_peptides = tf.data.TextLineDataset(\"/content/AMPs_toy.txt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RpdOl9QcymO",
        "outputId": "d055cea3-782d-4284-aaba-a7abc5452921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# Each elemet is has tf.Tensor structure\n",
        "for peptide in tf_peptides:\n",
        "  print(peptide)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'MPKTRRRPRRSQRKRPPTPWPYGRKKRRQRRR', shape=(), dtype=string)\n",
            "tf.Tensor(b'KLWKLWLKWLL', shape=(), dtype=string)\n",
            "tf.Tensor(b'GINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYE', shape=(), dtype=string)\n",
            "tf.Tensor(b'IKELLPHLSGIIDSVANAIK', shape=(), dtype=string)\n",
            "tf.Tensor(b'FLPLIGKVLSSIL', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUdG8yepc-T9"
      },
      "source": [
        "# 2. Step: Create vocabulary and instantiate TokenTextEncoder as encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjLHgRFB6BwJ",
        "outputId": "052e64e2-867f-423f-8d14-4e28e2e0c44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_list = set()\n",
        "for i in tf_peptides:\n",
        "  i = i.numpy()\n",
        "  j = list(i.decode(\"utf-8\"))\n",
        "  vocab_list.update(j)\n",
        "\n",
        "print(vocab_list)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'V', 'M', 'G', 'T', 'K', 'L', 'E', 'I', 'S', 'Q', 'N', 'D', 'H', 'Y', 'A', 'F', 'W', 'R', 'P'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8TfoIhU6_uu"
      },
      "source": [
        "encoder = tfds.deprecated.text.TokenTextEncoder(vocab_list=vocab_list, decode_token_separator=\"\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbpi98kXdUio"
      },
      "source": [
        "# 3. Create a function to map a word/peptide into a list of letters or aminoacids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1rAk3ZL_XUK"
      },
      "source": [
        "def encoder_fn(peptide):\n",
        "  peptide = peptide.numpy()\n",
        "  encoded_peptide = encoder.encode(\" \".join(peptide.decode(\"utf-8\")))\n",
        "  return [encoded_peptide]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdEtJdyzDjhN",
        "outputId": "515cfc1c-69e8-408c-acf9-bd0e7b4ba82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "for i in tf_peptides.take(2):\n",
        "  print(i)\n",
        "  encoded_peptide = encoder_fn(i)\n",
        "  print(encoded_peptide)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'MPKTRRRPRRSQRKRPPTPWPYGRKKRRQRRR', shape=(), dtype=string)\n",
            "[[2, 19, 5, 4, 18, 18, 18, 19, 18, 18, 9, 10, 18, 5, 18, 19, 19, 4, 19, 17, 19, 14, 3, 18, 5, 5, 18, 18, 10, 18, 18, 18]]\n",
            "tf.Tensor(b'KLWKLWLKWLL', shape=(), dtype=string)\n",
            "[[5, 6, 17, 5, 6, 17, 6, 5, 17, 6, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt9XcWFPkyUQ"
      },
      "source": [
        "Create a tf.py_function wrapper So you can .map this function directly. The tf.py_function will pass regular tensors (with a value and a .numpy() method to access it), to the wrapped python function.\n",
        "You want to use Dataset.map to apply this function to each element of the dataset. Dataset.map runs in graph mode.\n",
        "\n",
        "  * Graph tensors do not have a value.\n",
        "  * In graph mode you can only use TensorFlow Ops and functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCvKCXAO_QVa"
      },
      "source": [
        "def encode_map_fn(peptide):\n",
        "  # py_func doesn't set the shape of the returned tensors.\n",
        "  encoded_peptide = tf.py_function(encoder_fn,\n",
        "                                   inp=[peptide],\n",
        "                                   Tout=(tf.int64))\n",
        "  \n",
        "  # `tf.data.Datasets` work best if all components have a shape set\n",
        "  #  so set the shapes manually: \n",
        "  encoded_peptide.set_shape([None])\n",
        "  return encoded_peptide"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Pd0Kt7d2-o"
      },
      "source": [
        "# 4. Map encode function through elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIVVngs-ahGc"
      },
      "source": [
        "tf_peptides_encoded = tf_peptides.map(encode_map_fn)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J8p4C53eeyA"
      },
      "source": [
        "# 5. Create function to create windowed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkolxttPPAO9"
      },
      "source": [
        "def window_map(x):\n",
        "  \"\"\"\n",
        "  input: \n",
        "   x: tf.Tensor\n",
        "   window_size: int (global)\n",
        "  output: _VariantDataset \n",
        "  \"\"\"  \n",
        "  # cast tf.tensor to a tf.data, this way we can use the methods window and batch\n",
        "  x = tf.data.Dataset.from_tensor_slices(x)\n",
        "  \n",
        "  # Create windows of size window_size, the result is a _VariantDataset, this is\n",
        "  # why we need to extract its elements by using a batch with a buffer size \n",
        "  # equivalent a window_size \n",
        "  \n",
        "  x = x.window(window_size, 1, drop_remainder=True)\n",
        "  x = x.flat_map(lambda x: x.batch(window_size))\n",
        "  return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_ON2yqMldg3"
      },
      "source": [
        "Applies the window_map function to the encoded dataset \"tf_peptides_encoded\" thhrough a flat_map. We are taking a window size equal to 4, this means our features and labels\n",
        "length is going to be equal to 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzkI4r_pfMVw"
      },
      "source": [
        "window_size = 4\n",
        "b_flat = tf_peptides_encoded.flat_map(window_map).batch(5)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTdJN3qDgiTg",
        "outputId": "cb35fd12-983b-42fe-8ff7-0234b35000d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "for i in b_flat.take(3):\n",
        "  print(i)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 2 19  5  4]\n",
            " [19  5  4 18]\n",
            " [ 5  4 18 18]\n",
            " [ 4 18 18 18]\n",
            " [18 18 18 19]], shape=(5, 4), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[18 18 19 18]\n",
            " [18 19 18 18]\n",
            " [19 18 18  9]\n",
            " [18 18  9 10]\n",
            " [18  9 10 18]], shape=(5, 4), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[ 9 10 18  5]\n",
            " [10 18  5 18]\n",
            " [18  5 18 19]\n",
            " [ 5 18 19 19]\n",
            " [18 19 19  4]], shape=(5, 4), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfNhj_Eeg_gD"
      },
      "source": [
        "# 6. Create datasets with features and labels\n",
        "At this moment we have out data pipeline all setup to train a amp generation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiudiRoNhE8l"
      },
      "source": [
        "def label_feature(x):\n",
        "  feature = x[:-1]\n",
        "  label = x[1:]\n",
        "\n",
        "  return feature, label"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd_L1m1Kh-3B"
      },
      "source": [
        "b_flat_ds = tf_peptides_encoded.flat_map(window_map).map(label_feature)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMsCKut7hlGo",
        "outputId": "128b3431-4dc1-478a-f33b-3881088393e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for i in b_flat_ds.take(3):\n",
        "  print(i)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 2, 19,  5])>, <tf.Tensor: shape=(3,), dtype=int64, numpy=array([19,  5,  4])>)\n",
            "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([19,  5,  4])>, <tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 5,  4, 18])>)\n",
            "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 5,  4, 18])>, <tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 4, 18, 18])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhoYJ1WroDkd"
      },
      "source": [
        "# Adding repeat and shuffle to our data pipeline\n",
        "Now we have confidence in the pipelines quality we can integrate repeat, shuffle and batch functions to the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtGcr5sSnshe"
      },
      "source": [
        "feature_label_ds = tf_peptides_encoded.flat_map(window_map).map(label_feature).shuffle(3).repeat(10).batch(3)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGMLJAFqn6rl",
        "outputId": "347c98d1-0c6c-4de2-a204-4f104fe0b7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "for i in feature_label_ds.take(4):\n",
        "  print(i)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[19,  5,  4],\n",
            "       [ 5,  4, 18],\n",
            "       [ 2, 19,  5]])>, <tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[ 5,  4, 18],\n",
            "       [ 4, 18, 18],\n",
            "       [19,  5,  4]])>)\n",
            "(<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[18, 18, 19],\n",
            "       [18, 19, 18],\n",
            "       [ 4, 18, 18]])>, <tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[18, 19, 18],\n",
            "       [19, 18, 18],\n",
            "       [18, 18, 18]])>)\n",
            "(<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[19, 18, 18],\n",
            "       [18,  9, 10],\n",
            "       [ 9, 10, 18]])>, <tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[18, 18,  9],\n",
            "       [ 9, 10, 18],\n",
            "       [10, 18,  5]])>)\n",
            "(<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[18, 18,  9],\n",
            "       [18,  5, 18],\n",
            "       [10, 18,  5]])>, <tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
            "array([[18,  9, 10],\n",
            "       [ 5, 18, 19],\n",
            "       [18,  5, 18]])>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMPs data pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeFx0wFTkchmirGFdghFW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anvelezec/hans_on/blob/master/AMPs_data_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeKHw9xx4p0Y"
      },
      "source": [
        "!pip install -q tfds-nightly"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXrg66Gu4syf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrvJTJXZjmMC"
      },
      "source": [
        "# Data base consolidation\n",
        "There are plenty of antimicrobial peptides (AMPs) databases on the web, some useful links that centralize universities, research groups or laboratories metadata to download them are [[1]](http://crdd.osdd.net/raghava/satpdb/links.php), [[2]](http://www.uwm.edu.pl/biochemia/index.php/en/biopep/32-bioactive-peptide-databases):\n",
        " \n",
        "Sometimes the discovered AMPs are able to be downloaded in a fasta, csv or txt format. In other occasions we should use web scraping to consolidate peptides and its properties.\n",
        " \n",
        "During this notebook we are going to focus on the data pipeline creation, and we are using a toy database of 5  AMPs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reh5I_mxjfL0"
      },
      "source": [
        "amps_toy = [\"MPKTRRRPRRSQRKRPPTPWPYGRKKRRQRRR\",\n",
        "            \"KLWKLWLKWLL\",\n",
        "            \"GINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYE\",\n",
        "            \"IKELLPHLSGIIDSVANAIK\",\n",
        "            \"FLPLIGKVLSSIL\"]\n",
        "\n",
        "with open(\"AMPs_toy.txt\", \"w\") as file:\n",
        "  for amp in amps_toy:\n",
        "    file.write(amp + \"\\n\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxDpgka6cfp-"
      },
      "source": [
        "# 1. Step load dataset with tf.data.TextLineDataset\n",
        "Since we would not load all our dataset in memory we use tf.data.TextLineDataset [[3]](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset#top_of_page) to read batches of AMPs and feed them into a model. This way we could scale our computing capacity at different dataset sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj_-bnsD4_1D"
      },
      "source": [
        "tf_peptides = tf.data.TextLineDataset(\"/content/AMPs_toy.txt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RpdOl9QcymO",
        "outputId": "488a149e-914f-4d23-b7c8-2cfb9f291fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# Each elemet is has tf.Tensor structure\n",
        "for peptide in tf_peptides:\n",
        "  print(peptide)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'MPKTRRRPRRSQRKRPPTPWPYGRKKRRQRRR', shape=(), dtype=string)\n",
            "tf.Tensor(b'KLWKLWLKWLL', shape=(), dtype=string)\n",
            "tf.Tensor(b'GINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYE', shape=(), dtype=string)\n",
            "tf.Tensor(b'IKELLPHLSGIIDSVANAIK', shape=(), dtype=string)\n",
            "tf.Tensor(b'FLPLIGKVLSSIL', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUdG8yepc-T9"
      },
      "source": [
        "# 2. Step: Create vocabulary and instantiate TokenTextEncoder as encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjLHgRFB6BwJ",
        "outputId": "3beb0757-9044-407c-c3d5-736b2d5c143f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_list = set()\n",
        "for i in tf_peptides:\n",
        "  i = i.numpy()\n",
        "  j = list(i.decode(\"utf-8\"))\n",
        "  vocab_list.update(j)\n",
        "\n",
        "print(vocab_list)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'M', 'W', 'Y', 'I', 'K', 'H', 'G', 'E', 'R', 'T', 'D', 'P', 'Q', 'F', 'S', 'L', 'A', 'N', 'V'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8TfoIhU6_uu"
      },
      "source": [
        "encoder = tfds.deprecated.text.TokenTextEncoder(vocab_list=vocab_list, decode_token_separator=\"\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbpi98kXdUio"
      },
      "source": [
        "# 3. Create a function to map a word/peptide into a list of letters or aminoacids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1rAk3ZL_XUK"
      },
      "source": [
        "def encoder_fn(peptide):\n",
        "  peptide = peptide.numpy()\n",
        "  encoded_peptide = encoder.encode(\" \".join(peptide.decode(\"utf-8\")))\n",
        "  return [encoded_peptide]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdEtJdyzDjhN",
        "outputId": "0659a7ee-5293-4faf-c0a0-bf237fda2f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "for i in tf_peptides.take(2):\n",
        "  print(i)\n",
        "  encoded_peptide = encoder_fn(i)\n",
        "  print(encoded_peptide)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'MPKTRRRPRRSQRKRPPTPWPYGRKKRRQRRR', shape=(), dtype=string)\n",
            "[[1, 12, 5, 10, 9, 9, 9, 12, 9, 9, 15, 13, 9, 5, 9, 12, 12, 10, 12, 2, 12, 3, 7, 9, 5, 5, 9, 9, 13, 9, 9, 9]]\n",
            "tf.Tensor(b'KLWKLWLKWLL', shape=(), dtype=string)\n",
            "[[5, 16, 2, 5, 16, 2, 16, 5, 2, 16, 16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt9XcWFPkyUQ"
      },
      "source": [
        "Create a tf.py_function wrapper So you can .map this function directly. The tf.py_function will pass regular tensors (with a value and a .numpy() method to access it), to the wrapped python function.\n",
        "You want to use Dataset.map to apply this function to each element of the dataset. Dataset.map runs in graph mode.\n",
        "\n",
        "  * Graph tensors do not have a value.\n",
        "  * In graph mode you can only use TensorFlow Ops and functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCvKCXAO_QVa"
      },
      "source": [
        "def encode_map_fn(peptide):\n",
        "  # py_func doesn't set the shape of the returned tensors.\n",
        "  encoded_peptide = tf.py_function(encoder_fn,\n",
        "                                   inp=[peptide],\n",
        "                                   Tout=(tf.int64))\n",
        "  \n",
        "  # `tf.data.Datasets` work best if all components have a shape set\n",
        "  #  so set the shapes manually: \n",
        "  encoded_peptide.set_shape([None])\n",
        "  return encoded_peptide"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Pd0Kt7d2-o"
      },
      "source": [
        "# 4. Map encode function through elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIVVngs-ahGc"
      },
      "source": [
        "tf_peptides_encoded = tf_peptides.map(encode_map_fn)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J8p4C53eeyA"
      },
      "source": [
        "# 5. Create function to create windowed dataset\n",
        "For more details and examples to undestand this window concept visit [[4]](https://colab.research.google.com/github/ageron/handson-ml2/blob/master/16_nlp_with_rnns_and_attention.ipynb#scrollTo=hhijmvoGyVVF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkolxttPPAO9"
      },
      "source": [
        "def window_map(x):\n",
        "  \"\"\"\n",
        "  input: \n",
        "   x: tf.Tensor\n",
        "   window_size: int (global)\n",
        "  output: _VariantDataset \n",
        "  \"\"\"  \n",
        "  # cast tf.tensor to a tf.data, this way we can use the methods window and batch\n",
        "  x = tf.data.Dataset.from_tensor_slices(x)\n",
        "  \n",
        "  # Create windows of size window_size, the result is a _VariantDataset, this is\n",
        "  # why we need to extract its elements by using a batch with a buffer size \n",
        "  # equivalent a window_size \n",
        "  \n",
        "  x = x.window(window_size, 1, drop_remainder=True)\n",
        "  x = x.flat_map(lambda x: x.batch(window_size))\n",
        "  return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_ON2yqMldg3"
      },
      "source": [
        "Applies the window_map function to the encoded dataset \"tf_peptides_encoded\" thhrough a flat_map. We are taking a window size equal to 4, this means our features and labels\n",
        "length is going to be equal to 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzkI4r_pfMVw"
      },
      "source": [
        "window_size = 10\n",
        "b_flat = tf_peptides_encoded.flat_map(window_map).batch(5)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTdJN3qDgiTg",
        "outputId": "db192db0-f6d9-47d1-c0af-561056866e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "for i in b_flat.take(3):\n",
        "  print(i)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1 12  5 10  9  9  9 12  9  9]\n",
            " [12  5 10  9  9  9 12  9  9 15]\n",
            " [ 5 10  9  9  9 12  9  9 15 13]\n",
            " [10  9  9  9 12  9  9 15 13  9]\n",
            " [ 9  9  9 12  9  9 15 13  9  5]], shape=(5, 10), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[ 9  9 12  9  9 15 13  9  5  9]\n",
            " [ 9 12  9  9 15 13  9  5  9 12]\n",
            " [12  9  9 15 13  9  5  9 12 12]\n",
            " [ 9  9 15 13  9  5  9 12 12 10]\n",
            " [ 9 15 13  9  5  9 12 12 10 12]], shape=(5, 10), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[15 13  9  5  9 12 12 10 12  2]\n",
            " [13  9  5  9 12 12 10 12  2 12]\n",
            " [ 9  5  9 12 12 10 12  2 12  3]\n",
            " [ 5  9 12 12 10 12  2 12  3  7]\n",
            " [ 9 12 12 10 12  2 12  3  7  9]], shape=(5, 10), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfNhj_Eeg_gD"
      },
      "source": [
        "# 6. Create datasets with features and labels\n",
        "At this moment we have out data pipeline all setup to train a amp generation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiudiRoNhE8l"
      },
      "source": [
        "def label_feature(x):\n",
        "  feature = x[:-1]\n",
        "  label = x[1:]\n",
        "\n",
        "  return feature, label"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd_L1m1Kh-3B"
      },
      "source": [
        "b_flat_ds = tf_peptides_encoded.flat_map(window_map).map(label_feature)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMsCKut7hlGo",
        "outputId": "d1f162c7-1ea2-4c1c-81db-af529cadd28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for i in b_flat_ds.take(3):\n",
        "  print(i)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(9,), dtype=int64, numpy=array([ 1, 12,  5, 10,  9,  9,  9, 12,  9])>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([12,  5, 10,  9,  9,  9, 12,  9,  9])>)\n",
            "(<tf.Tensor: shape=(9,), dtype=int64, numpy=array([12,  5, 10,  9,  9,  9, 12,  9,  9])>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([ 5, 10,  9,  9,  9, 12,  9,  9, 15])>)\n",
            "(<tf.Tensor: shape=(9,), dtype=int64, numpy=array([ 5, 10,  9,  9,  9, 12,  9,  9, 15])>, <tf.Tensor: shape=(9,), dtype=int64, numpy=array([10,  9,  9,  9, 12,  9,  9, 15, 13])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhoYJ1WroDkd"
      },
      "source": [
        "# Adding repeat and shuffle to our data pipeline\n",
        "Now we have confidence in the pipelines quality we can integrate repeat, shuffle and batch functions to the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtGcr5sSnshe"
      },
      "source": [
        "feature_label_ds = tf_peptides_encoded.flat_map(window_map).map(label_feature).shuffle(3).repeat(10).batch(3)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGMLJAFqn6rl",
        "outputId": "aeedecc1-f791-4505-f226-629e14dcb720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "for i in feature_label_ds.take(4):\n",
        "  print(i)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[ 5, 10,  9,  9,  9, 12,  9,  9, 15],\n",
            "       [ 1, 12,  5, 10,  9,  9,  9, 12,  9],\n",
            "       [ 9,  9,  9, 12,  9,  9, 15, 13,  9]])>, <tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[10,  9,  9,  9, 12,  9,  9, 15, 13],\n",
            "       [12,  5, 10,  9,  9,  9, 12,  9,  9],\n",
            "       [ 9,  9, 12,  9,  9, 15, 13,  9,  5]])>)\n",
            "(<tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[ 9,  9, 12,  9,  9, 15, 13,  9,  5],\n",
            "       [12,  5, 10,  9,  9,  9, 12,  9,  9],\n",
            "       [ 9, 12,  9,  9, 15, 13,  9,  5,  9]])>, <tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[ 9, 12,  9,  9, 15, 13,  9,  5,  9],\n",
            "       [ 5, 10,  9,  9,  9, 12,  9,  9, 15],\n",
            "       [12,  9,  9, 15, 13,  9,  5,  9, 12]])>)\n",
            "(<tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[ 9,  9, 15, 13,  9,  5,  9, 12, 12],\n",
            "       [ 9, 15, 13,  9,  5,  9, 12, 12, 10],\n",
            "       [10,  9,  9,  9, 12,  9,  9, 15, 13]])>, <tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[ 9, 15, 13,  9,  5,  9, 12, 12, 10],\n",
            "       [15, 13,  9,  5,  9, 12, 12, 10, 12],\n",
            "       [ 9,  9,  9, 12,  9,  9, 15, 13,  9]])>)\n",
            "(<tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[15, 13,  9,  5,  9, 12, 12, 10, 12],\n",
            "       [12,  9,  9, 15, 13,  9,  5,  9, 12],\n",
            "       [ 9,  5,  9, 12, 12, 10, 12,  2, 12]])>, <tf.Tensor: shape=(3, 9), dtype=int64, numpy=\n",
            "array([[13,  9,  5,  9, 12, 12, 10, 12,  2],\n",
            "       [ 9,  9, 15, 13,  9,  5,  9, 12, 12],\n",
            "       [ 5,  9, 12, 12, 10, 12,  2, 12,  3]])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2zyPNocpJe3"
      },
      "source": [
        "# References\n",
        "[1] http://crdd.osdd.net/raghava/satpdb/links.php\n",
        "\n",
        "[2] http://www.uwm.edu.pl/biochemia/index.php/en/biopep/32-bioactive-peptide-databases\n",
        "\n",
        "[3] https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset#top_of_page\n",
        "\n",
        "[4] https://colab.research.google.com/github/ageron/handson-ml2/blob/master/16_nlp_with_rnns_and_attention.ipynb#scrollTo=hhijmvoGyVVF"
      ]
    }
  ]
}